---
layout: post
title: "word-cloud 개발자의 개발과정기록"
author: "OSS-5"
---

## 1. 개발하게 된 계기

 독일 파이썬 컨퍼런스인 Pycon DE에 참가해서 scikit-learn 작업을 많이 하고 돌아오는 길에, 뭔가 다른걸 해보기로 했다. 사실 꽤 이전부터 계획했던 일인데, 그것은 wordle 같은 word cloud를 만드는 것이다.

 나도 물론 word cloud 같은 것이 좀 구식인 것은 알고있지만 어쨌든 나는 word cloud를 좋아한다. word cloud를 만들 때 시각화를 좀더 흥미롭게 하기 위해서 topic-model을 활용할 수 있겠다는 생각이 들었다.

 그래서 나는 쓸만한 word cloud 오픈소스를 찾았는데, 하나도 발견하지 못했다. (이건 예전 일이니 지금은 좀 다를 수도 있겠다.)

 돌아오는 기차 안에서 심심했던 차에 코드를 구상했다.

## 2. 초기 개발 과정 및 개발 과정 중 어려움

 우선 문서를 불러와야 했다. 나는 미국 헌법 조문을 사용했다.

```
 with open("constitution.txt") as f:
        lines f.readlines()                                                                            
    text = "".join(lines) 
```

 그 다음에는 단어에 비중을 두어서 추출해야 했다. 예를 들어 그 문서에서 단어가 얼마나 자주 등장하는지를 기준으로 하고자 했다. 나는 scikit-learn의  CountVectorizer(역주 : 단어들의 출현빈도로 문서들을 벡터화하는 클래스. 또한 이 과정에서 모두 소문자로 변환한다) 를 사용했다. 
 
 나는 가장 많이 등장하는 200개의 단어를의 출현빈도를 얻었고, 가장 많이 등장하는 출현빈도를 통해 정규화하였다.

```
cv = CountVectorizer(min_df=0, charset_error="ignore",                                               
                         stop_words="english", max_features=200)
counts = cv.fit_transform([text]).toarray().ravel()                                                  
words = np.array(cv.get_feature_names()) 
# normalize                                                                                                                                             
counts = counts / float(counts.max())

```


